{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808377ac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# FaceSigns Watermark Testing & Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74dffda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import torch.nn.functional as F\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import image_transforms\n",
    "\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9da3c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_dir = \"sample_images\"\n",
    "#img_dir = r'C:\\Users\\Odyss\\PycharmProjects\\deepfake_watermarking\\FaceSigns\\sample_images\\celeba_data.zip'\n",
    "#img_dir = r'\\sample_images\\celeba_data.zip'\n",
    "\n",
    "working_dir = str(Path.cwd()) \n",
    "img_dir = working_dir + '\\\\sample_images\\\\celeba_data.zip'\n",
    "\n",
    "target_image_dir = \"sample_target_images\"\n",
    "out_dir = \"out_dir\"\n",
    "encoder_model_path = \"encoder_model.pth\"\n",
    "decoder_model_path = \"decoder_model.pth\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder_model = torch.jit.load(\"encoder_model.pth\", map_location=torch.device('cpu'))\n",
    "decoder_model = torch.jit.load(\"decoder_model.pth\", map_location=torch.device('cpu'))\n",
    "encoder_model.eval().to(device)\n",
    "decoder_model.eval().to(device)\n",
    "clear_output()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def showarray(a, fmt='png'):\n",
    "    \"\"\"\n",
    "    takes a numpy array (0 to 1) of size h, w, 3\n",
    "    \"\"\"\n",
    "    a = np.uint8(a*255.)\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "    \n",
    "def text_to_bits(text, encoding='utf-8', errors='surrogatepass'):\n",
    "    bits = bin(int.from_bytes(text.encode(encoding, errors), 'big'))[2:]\n",
    "    return bits.zfill(8 * ((len(bits) + 7) // 8))\n",
    "\n",
    "def text_from_bits(bits, encoding='utf-8', errors='surrogatepass'):\n",
    "    n = int(bits, 2)\n",
    "    return n.to_bytes((n.bit_length() + 7) // 8, 'big').decode(encoding, errors) or '\\0'\n",
    "\n",
    "def load_images(image_filepaths, img_size=256):\n",
    "    i = 0 \n",
    "    print(\"Loading images\")\n",
    "    image_batch_np = []\n",
    "    for file_path in image_filepaths:\n",
    "        if (i % 100 == 0):\n",
    "            print(i)\n",
    "        image_from_file = skimage.io.imread(file_path)/255.0\n",
    "        \n",
    "        image_from_file = skimage.transform.resize(image_from_file, (300,300),\n",
    "                                                   preserve_range=True, mode='constant')\n",
    "        \n",
    "        image_from_file = image_from_file[:, :, :3]\n",
    "\n",
    "\n",
    "        image_batch_np.append(image_from_file)\n",
    "        i = i + 1\n",
    "    image_batch_np = np.stack(image_batch_np, axis=0)\n",
    "    image_batch = torch.from_numpy(image_batch_np).float()\n",
    "    image_batch = image_batch.permute(0, 3, 1, 2)\n",
    "\n",
    "    h, w = image_batch.shape[2:]\n",
    "    if h > w:\n",
    "        image_batch = image_batch[:, :, int((h-w)/2):int((h+w)/2), :]\n",
    "    elif w > h:\n",
    "        image_batch = image_batch[:, :, :, int((w-h)/2):int((w+h)/2)]\n",
    "    image_batch = F.interpolate(image_batch, size=(img_size, img_size), mode='bilinear', align_corners=True)\n",
    "\n",
    "    return image_batch\n",
    "\n",
    "def save_images(image_batch, out_dir, prefix=\"\"):\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    \n",
    "    image_paths = []\n",
    "    for img_idx in range(image_batch.shape[0]):\n",
    "        image_np = image_batch[img_idx].permute(1, 2, 0).cpu().numpy()\n",
    "        image_np = np.uint8(image_np*255.)\n",
    "        file_path = os.path.join(out_dir, \"{}_{}.png\".format(prefix, img_idx))\n",
    "        PIL.Image.fromarray(image_np).save(file_path)\n",
    "        image_paths.append(file_path)\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "def find_image_paths(image_dir):\n",
    "  \n",
    "    image_paths = []\n",
    "\n",
    "    if image_dir == \"sample_images\" or image_dir == \"alternate_deepfakes\" or image_dir == \"sample_target_images\":\n",
    "        for img_file in os.listdir(image_dir):\n",
    "            if img_file.endswith(\".png\") or img_file.endswith(\".jpg\"):\n",
    "                image_paths.append(os.path.join(image_dir, img_file))\n",
    "    else:\n",
    "        with ZipFile(img_dir) as zip_archive: \n",
    "            for img_file in zip_archive.filelist:\n",
    "                image_paths.append(os.path.join(image_dir, img_file.filename))\n",
    "    \n",
    "    image_paths.sort()\n",
    "    return image_paths\n",
    "\n",
    "def decode_images(image_paths, secret_numpy, decoder_model):\n",
    "    image_batch = load_images(image_paths)\n",
    "    with torch.no_grad():\n",
    "        image_batch = image_batch.to(device)\n",
    "        decoded_secrets, _ = decoder_model(image_batch)\n",
    "\n",
    "    predicted_secrets = (F.sigmoid(decoded_secrets) > 0.5).long()\n",
    "    secrets = torch.from_numpy(secret_numpy).repeat(predicted_secrets.shape[0], 1).to(device) \n",
    "    secret_accuracy = (predicted_secrets == secrets).float().mean().item()\n",
    "\n",
    "    decoding_results = []\n",
    "    for img_idx, image_path in enumerate(image_paths):\n",
    "        image_predicted_secret = predicted_secrets[img_idx].cpu().numpy().tolist()\n",
    "        image_predicted_secret_bits = \"\".join([str(b) for b in image_predicted_secret][:secrete_num_bits])\n",
    "        try:\n",
    "            image_predicted_secret_text = text_from_bits(image_predicted_secret_bits)\n",
    "        except:\n",
    "            image_predicted_secret_text = \"could not decode\"\n",
    "        \n",
    "        decoding_results.append({\n",
    "            \"image_path\": image_path,\n",
    "            \"image_predicted_secret_text\": image_predicted_secret_text,\n",
    "            \"bit_accuracy\": (predicted_secrets[img_idx] == secrets[img_idx]).float().mean().item()\n",
    "        })\n",
    "    \n",
    "    return secret_accuracy, decoding_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#original_image_paths = find_image_paths(img_dir) #returns image path that has all images \n",
    "#img_dir = r'C:\\Users\\Odyss\\PycharmProjects\\deepfake_watermarking\\FaceSigns\\sample_images\\celeba_data.zip'\n",
    "working_dir = str(Path.cwd()) \n",
    "img_dir = working_dir + '\\\\sample_images\\\\celeba_data.zip'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Watermark 'secret' value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert text to secret bits\n",
    "secret_text = \"sample\"\n",
    "secret_size = 128\n",
    "secret_bits = text_to_bits(secret_text)\n",
    "secrete_num_bits = len(secret_bits)\n",
    "\n",
    "assert secrete_num_bits <= secret_size\n",
    "\n",
    "secret_bits = secret_bits + \"\".join([\"0\"]*(secret_size-secrete_num_bits))   #Pad secret bits with zeroes until 128bits\n",
    "secret_numpy = np.array([[ int(c) for c in  secret_bits ]])                #Convert to array "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Change value here to load more images "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_image_paths = find_image_paths(img_dir) #returns image path that has all images \n",
    "original_image_paths = original_image_paths[1000:1500]\n",
    "\n",
    "images = load_images(original_image_paths)\n",
    "images = images.to(device)\n",
    "secrets = torch.from_numpy(secret_numpy).repeat(images.shape[0], 1).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Watermark Images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        \n",
    "    encoded_images, secret_images = encoder_model(images, secrets)\n",
    "    signed_image_dir = os.path.join(out_dir, \"signed_images\")\n",
    "    encoded_image_paths = save_images(encoded_images, signed_image_dir)\n",
    "\n",
    "\n",
    "for sidx in range(5):\n",
    "    original_image_numpy = images[sidx].permute(1, 2, 0).cpu().numpy() \n",
    "    encoded_image_numpy = encoded_images[sidx].permute(1, 2, 0).cpu().numpy()\n",
    "    residual = (encoded_image_numpy - original_image_numpy)\n",
    "    rmin, rmax = np.min(residual), np.max(residual)\n",
    "    residual_scaled = (residual-rmin)/(rmax - rmin)\n",
    "    original_encoded_image = np.concatenate( (original_image_numpy, encoded_image_numpy, residual_scaled), axis=1)\n",
    "    print(\"Original Image,\", \"Signed Image,\", \"Perturbation (Scaled for Visualization)\")\n",
    "    showarray(original_encoded_image)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split Dataset In half"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_images = len(encoded_image_paths)\n",
    "print('Total Images: ', total_images)\n",
    "\n",
    "half = int(total_images/2)\n",
    "benign_encoded_image_paths = encoded_image_paths[:half]\n",
    "mal_encoded_image_paths = encoded_image_paths[half:]\n",
    "\n",
    "print('Benign Transformations: ', len(benign_encoded_image_paths))\n",
    "print('Malicous Transformations: ', len(mal_encoded_image_paths))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make Benign Transformations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "benign_dir = os.path.join(out_dir, \"benign_transformed_images\")\n",
    "benign_tranform_list, benign_file_paths = image_transforms.apply_benign_transforms(benign_encoded_image_paths, benign_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decode benign Images and classify as Benign or Malicous based on Bit Recovery Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#For filter in filter list, decode_image \n",
    "for key in benign_tranform_list:\n",
    "    secret_accuracy, decoding_results = decode_images(benign_file_paths[key], secret_numpy, decoder_model)\n",
    "    \n",
    "    for row in decoding_results:\n",
    "        BRA = row['bit_accuracy']\n",
    "        if BRA >= 0.95:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display Example Benign Transformation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for row in decoding_results[:1]:\n",
    "        IPython.display.display(IPython.display.Image(row['image_path']))\n",
    "        print(\"Transform : {}\".format(key))\n",
    "        print(\"Predicted secret: {}\".format(row['image_predicted_secret_text']))\n",
    "        print(\"Bit accuracy: {}\".format(row['bit_accuracy']))\n",
    "        print(\"Image path: {}\".format(row['image_path']))\n",
    "        print (\"-----------------------------------------------------\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for row in decoding_results[:1]:\n",
    "        IPython.display.display(IPython.display.Image(row['image_path']))\n",
    "        print(\"Transform : {}\".format(key))\n",
    "        print(\"Predicted secret: {}\".format(row['image_predicted_secret_text']))\n",
    "        print(\"Bit accuracy: {}\".format(row['bit_accuracy']))\n",
    "        print(\"Image path: {}\".format(row['image_path']))\n",
    "        print (\"-----------------------------------------------------\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make Malicous Tranformations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FaceSwap Algorithm \n",
    "Is unable to swap faces when the sample image is not a face-forward picture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "mal_dir = os.path.join(out_dir, \"mal_transformed_images\")\n",
    "target_image_paths = find_image_paths(target_image_dir)\n",
    "\n",
    "unable_to_malicously_swap, mal_tranform_list, mal_file_paths = image_transforms.apply_malicious_transforms(\n",
    "    mal_encoded_image_paths, target_image_paths[1:2], mal_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unable_to_malicously_swap"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decode malicous Images and classify as Benign or Malicous based on Bit Recovery Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key in mal_tranform_list:\n",
    "    secret_accuracy, decoding_results = decode_images(mal_file_paths[key], secret_numpy, decoder_model)\n",
    "        \n",
    "    for row in decoding_results:\n",
    "        BRA = row['bit_accuracy']\n",
    "        if BRA >= 0.95:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)  \n",
    "            \"\"\"\n",
    "            if BRA > 0.50:\n",
    "                print(\"Transform : {}\".format(key))\n",
    "                print(\"Predicted secret: {}\".format(row['image_predicted_secret_text']))\n",
    "                print(\"Bit accuracy: {}\".format(row['bit_accuracy']))\n",
    "                IPython.display.display(IPython.display.Image(row['image_path']))\n",
    "                print (\"-----------------------------------------------------\\n\")\n",
    "            \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Adjust length to the images that were able to be swapped. \n",
    "if(unable_to_malicously_swap): \n",
    "    l = len(y_actual) - unable_to_malicously_swap \n",
    "    y_actual = y_actual[:l]\n",
    "    print(len(y_actual))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display Example Malcious Transformation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for row in decoding_results[23:24]:\n",
    "    IPython.display.display(IPython.display.Image(row['image_path']))\n",
    "    print(\"Transform : {}\".format(key))\n",
    "    print(\"Predicted secret: {}\".format(row['image_predicted_secret_text']))\n",
    "    print(\"Bit accuracy: {}\".format(row['bit_accuracy']))\n",
    "    print (\"-----------------------------------------------------\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyze Watermark Method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(y_pred))\n",
    "print(len(y_actual))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert(len(y_pred) == len(y_actual))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = y_pred \n",
    "actual = y_actual"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### AUC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "pred = y_pred\n",
    "actual = y_actual \n",
    "\n",
    "auc = metrics.roc_auc_score(actual, pred)\n",
    "auc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "from sklearn import metrics \n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual, pred)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix) #, display_labels = [False, True]\n",
    "cm_display.plot()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da926c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}